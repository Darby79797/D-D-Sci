{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8e1588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "url = \"https://raw.githubusercontent.com/H-B-P/d-and-d-sci-sep-2022/main/dset.csv\"\n",
    "df = pd.read_csv(url,index_col=0)\n",
    "df.columns = ['Intellect','Integrity','Courage','Reflexes','Patience','House','Rating','Year']\n",
    "url2 = \"https://raw.githubusercontent.com/H-B-P/d-and-d-sci-sep-2022/main/incoming_class.csv\"\n",
    "students = pd.read_csv(url2,index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b4e6f1",
   "metadata": {},
   "source": [
    "A solution to https://www.lesswrong.com/posts/DKDDT8hGCTz8AxBQF/d-and-d-sci-september-2022-the-allocation-helm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fe1a6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Intellect  Integrity  Courage  Reflexes  Patience           House  \\\n",
      "1             64         12       11        45        21      Serpentyne   \n",
      "2             58         54       15        24        34  Humblescrumble   \n",
      "3             48         44       32        23        58      Serpentyne   \n",
      "4             28         28       13        25        67      Serpentyne   \n",
      "5             33         38       28        28        33    Dragonslayer   \n",
      "...          ...        ...      ...       ...       ...             ...   \n",
      "20375         32         31       30        33        28   Thought-Talon   \n",
      "20376         18         13       32        20        53    Dragonslayer   \n",
      "20377         54         46       20        39        24   Thought-Talon   \n",
      "20378         39         61       14        14        24  Humblescrumble   \n",
      "20379         33         48        2        62        31      Serpentyne   \n",
      "\n",
      "       Rating  Year  \n",
      "1          26  1511  \n",
      "2          40  1511  \n",
      "3          34  1511  \n",
      "4          24  1511  \n",
      "5          36  1511  \n",
      "...       ...   ...  \n",
      "20375      30  2021  \n",
      "20376      19  2021  \n",
      "20377      22  2021  \n",
      "20378      46  2021  \n",
      "20379      34  2021  \n",
      "\n",
      "[20379 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f15cb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "recent = df[df.Year > 2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbd14633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Intellect  Integrity  Courage  Reflexes  Patience           House  \\\n",
      "20152          8         50       10        17        10  Humblescrumble   \n",
      "20153         39         39       25        43        32  Humblescrumble   \n",
      "20154         63         31       22        63        15  Humblescrumble   \n",
      "20155         28         28       24        36         8   Thought-Talon   \n",
      "20156         39         37       24        28         7   Thought-Talon   \n",
      "...          ...        ...      ...       ...       ...             ...   \n",
      "20375         32         31       30        33        28   Thought-Talon   \n",
      "20376         18         13       32        20        53    Dragonslayer   \n",
      "20377         54         46       20        39        24   Thought-Talon   \n",
      "20378         39         61       14        14        24  Humblescrumble   \n",
      "20379         33         48        2        62        31      Serpentyne   \n",
      "\n",
      "       Rating  Year  \n",
      "20152      16  2011  \n",
      "20153      26  2011  \n",
      "20154      20  2011  \n",
      "20155      11  2011  \n",
      "20156       6  2011  \n",
      "...       ...   ...  \n",
      "20375      30  2021  \n",
      "20376      19  2021  \n",
      "20377      22  2021  \n",
      "20378      46  2021  \n",
      "20379      34  2021  \n",
      "\n",
      "[228 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(recent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddffaa75",
   "metadata": {},
   "source": [
    "I am given that \"for the last decade\" allocations are random, and hence the 'recent' dataframe will have no selection effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e59279",
   "metadata": {},
   "source": [
    "Now, since the data is moderately high-dimensional, I thrash it with a linear regression to see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a54b4bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PuffR = recent[recent.House=='Humblescrumble']\n",
    "GriffR = recent[recent.House=='Dragonslayer']\n",
    "ClawR = recent[recent.House=='Thought-Talon']\n",
    "SlythR = recent[recent.House=='Serpentyne']\n",
    "\n",
    "Puff = df[df.House=='Humblescrumble']\n",
    "Griff = df[df.House=='Dragonslayer']\n",
    "Claw = df[df.House=='Thought-Talon']\n",
    "Slyth = df[df.House=='Serpentyne']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5ead2ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ 0.12446555  0.3263759   0.00741056 -0.0465382   0.17803888]\n",
      "Mean squared error: 35.14\n",
      "Coefficient of determination: 0.47\n"
     ]
    }
   ],
   "source": [
    "PuffPredictors = PuffR[['Intellect','Integrity','Courage','Reflexes','Patience']]\n",
    "PuffResults = PuffR['Rating']\n",
    "\n",
    "puff = Ridge(alpha=0.1)\n",
    "#puff = linear_model.LinearRegression()\n",
    "puff.fit(PuffPredictors, PuffResults)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "PuffPredictions = puff.predict(Puff[['Intellect','Integrity','Courage','Reflexes','Patience']])\n",
    "\n",
    "# The coefficients\n",
    "print(\"Coefficients: \\n\", puff.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(Puff['Rating'], PuffPredictions))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(Puff['Rating'], PuffPredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ff0ed5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [0.08800325 0.07668528 0.29141573 0.29281638 0.18630045]\n",
      "Mean squared error: 62.18\n",
      "Coefficient of determination: 0.37\n"
     ]
    }
   ],
   "source": [
    "GriffPredictors = GriffR[['Intellect','Integrity','Courage','Reflexes','Patience']]\n",
    "GriffResults = GriffR['Rating'] \n",
    "\n",
    "griff = Ridge(alpha=0.1)\n",
    "#griff = linear_model.LinearRegression()\n",
    "griff.fit(GriffPredictors, GriffResults)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "GriffPredictions = griff.predict(Griff[['Intellect','Integrity','Courage','Reflexes','Patience']])\n",
    "\n",
    "# The coefficients\n",
    "print(\"Coefficients: \\n\", griff.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(Griff['Rating'], GriffPredictions))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(Griff['Rating'], GriffPredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aba03901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [0.3792509  0.07694265 0.13598182 0.2007744  0.36543627]\n",
      "Mean squared error: 70.17\n",
      "Coefficient of determination: 0.46\n"
     ]
    }
   ],
   "source": [
    "ClawPredictors = ClawR[['Intellect','Integrity','Courage','Reflexes','Patience']]\n",
    "ClawResults = ClawR['Rating'] \n",
    "\n",
    "claw = Ridge(alpha=0.1)\n",
    "#claw = linear_model.LinearRegression()\n",
    "claw.fit(ClawPredictors, ClawResults)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "ClawPredictions = claw.predict(Claw[['Intellect','Integrity','Courage','Reflexes','Patience']])\n",
    "\n",
    "# The coefficients\n",
    "print(\"Coefficients: \\n\", claw.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(Claw['Rating'], ClawPredictions))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(Claw['Rating'], ClawPredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "21c35ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ 0.28151878  0.04703135 -0.02478481  0.15862298  0.24644294]\n",
      "Mean squared error: 68.10\n",
      "Coefficient of determination: 0.26\n"
     ]
    }
   ],
   "source": [
    "SlythPredictors = SlythR[['Intellect','Integrity','Courage','Reflexes','Patience']]\n",
    "SlythResults = SlythR['Rating'] \n",
    "\n",
    "slyth = Ridge(alpha=0.1)\n",
    "#slyth = linear_model.LinearRegression()\n",
    "slyth.fit(SlythPredictors, SlythResults)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "SlythPredictions = slyth.predict(Slyth[['Intellect','Integrity','Courage','Reflexes','Patience']])\n",
    "\n",
    "# The coefficients\n",
    "print(\"Coefficients: \\n\", slyth.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(Slyth['Rating'], SlythPredictions))\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(Slyth['Rating'], SlythPredictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fac79d",
   "metadata": {},
   "source": [
    "Observation 1: The full relation is definitely nonlinear.  \n",
    "Observation 2: The linear model does yield an indication as to which traits are important when giving a student to a specific House;   \n",
    "Humblescrumbles need primarily Integrity, and to a lesser extent Intelligence and Patience  \n",
    "Dragonslayers need primarily Courage and Reflexes, and secondarily Patience  \n",
    "Taloners need primarily Intelligence and Patience, and secondarily Reflexes  \n",
    "Serpentynes need more or less the same statistics as Taloners, with lower scores across the board.\n",
    "\n",
    "Finally, I observe that my MSE doesn't get much higher than (8.5)^2 when testing the linear model (trained on 10 years of students) on the whole dataset, and so if any student to be sorted gets a predicted score on one house that is >10 higher than their score in any other house, it's probably their best house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b24a64ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Intellect  Integrity  Courage  Reflexes  Patience  Year\n",
      "Student                                                         \n",
      "A               34         52       46        18        33  2022\n",
      "B               22         13       19        10        25  2022\n",
      "C               33         11       18        46        46  2022\n",
      "D                6         21       47        17        23  2022\n",
      "E               19         33       38         9        17  2022\n",
      "F               48          6       33        30        54  2022\n",
      "G               17         10       39        54        32  2022\n",
      "H               39         20       52        16         6  2022\n",
      "I                9         11        6        30        25  2022\n",
      "J               50         27        7        11        30  2022\n",
      "K               28         16       35        37        29  2022\n",
      "L                9         28       23        43        53  2022\n",
      "M               17         25       36        21        65  2022\n",
      "N               11         26       34        58        20  2022\n",
      "O               43         20        5        21        23  2022\n",
      "P               20          4        7        20        54  2022\n",
      "Q               37         45       26        33        38  2022\n",
      "R               52         61       13        31        29  2022\n",
      "S               44         14       14        27        41  2022\n",
      "T               32         63        6        32        29  2022\n"
     ]
    }
   ],
   "source": [
    "print(students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8c91b69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "students['PuffPredict'] = puff.predict(students[['Intellect','Integrity','Courage','Reflexes','Patience']])\n",
    "students['GriffPredict'] = griff.predict(students[['Intellect','Integrity','Courage','Reflexes','Patience']])\n",
    "students['ClawPredict'] = claw.predict(students[['Intellect','Integrity','Courage','Reflexes','Patience']])\n",
    "students['SlythPredict'] = slyth.predict(students[['Intellect','Integrity','Courage','Reflexes','Patience']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8839a2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         PuffPredict  GriffPredict  ClawPredict  SlythPredict\n",
      "Student                                                      \n",
      "A          29.540994     22.048093    23.636822     18.598527\n",
      "B          14.066657      6.300169     7.883854     10.814741\n",
      "C          16.839057     21.277118    26.667787     24.727899\n",
      "D          14.211866     15.342354     6.913420      6.610192\n",
      "E          18.983806     11.323544     7.744344      8.309734\n",
      "F          19.354241     23.390318    33.722664     27.777328\n",
      "G          11.812004     25.646436    19.868535     17.474869\n",
      "H          15.049783     16.166930    13.618475     11.381203\n",
      "I          10.768752      7.070679     5.047431     10.555597\n",
      "J          22.875684      7.565184    19.976250     21.043961\n",
      "K          15.366771     20.372140    19.448550     17.516983\n",
      "L          20.823214     22.351422    21.509430     19.896289\n",
      "M          24.096454     22.407442    26.048571     21.152752\n",
      "N          13.927553     23.823962    14.562065     14.339359\n",
      "O          17.993319      7.453593    15.960622     18.654809\n",
      "P          15.489162     10.267883    17.406482     18.858914\n",
      "Q          27.673670     21.270739    26.355137     23.221119\n",
      "R          33.157056     17.767011    27.816744     25.983373\n",
      "S          19.151695     14.814533    24.884552     23.818788\n",
      "T          31.222085     14.413223    19.634513     20.779177\n"
     ]
    }
   ],
   "source": [
    "print(students[['PuffPredict','GriffPredict','ClawPredict','SlythPredict']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4b3cd5",
   "metadata": {},
   "source": [
    "I hence have some predictions for which houses students should go into based on my linear regression model only.\n",
    "\n",
    "A: Humblescrumble (by 6)  \n",
    "B: Humblescrumble (by 3)  \n",
    "C: Thought-Talon (by 2)  \n",
    "D: Dragonslayer (by 1)  \n",
    "E: Humblescrumble (by 7)  \n",
    "F: Thought-Talon (by 6)  \n",
    "G: Dragonslayer (by 6)  \n",
    "H: Dragonslayer (by 2)  \n",
    "I: Serpentyne (~equal to Humblescrumble)  \n",
    "J: Humblescrumble (by 1) -- but switch to Serpentyne if balancing class sizes  \n",
    "K: Dragonslayer (by 1)  \n",
    "L: Dragonlayer (by 1) -- but switch to Thought-Talon if balancing class sizes  \n",
    "M: Thought-Talon (by 2)  \n",
    "N: Dragonlayer (by 9)  \n",
    "O: Serpentyne (by 1)  \n",
    "P: Serpentyne (by 1)  \n",
    "Q: Humblescrumble (by 1) -- but switch to Thought-Talon if balancing class sizes  \n",
    "R: Humblescrumble (by 5)  \n",
    "S: Thought-Talon (by 1)  -- but switch to Serpentyne if balancing class sizes  \n",
    "T: Humblescrumble (by 10).\n",
    "\n",
    "Now, based on genre of the data format, I consider it likely that I am penalised in some way for assigning students to Houses in non-equal quantities. If so, I change the house assignments of students J,L,Q and S as given above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5586160",
   "metadata": {},
   "source": [
    "Hypothesis; non-equal allocation to houses in a given year makes the year as a whole do worse. Let's test this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c390a814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
